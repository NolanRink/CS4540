{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHEhUsx4fICXpcHOqpQwfD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NolanRink/CS4540/blob/main/Project3/Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from scipy import signal, stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "files = {\n",
        "    \"Rat08_HPC\": \"Rat08-20130711_017.h5\",\n",
        "    \"SubjectHB10_BLA\": \"Part1SubjectHB10.h5\",\n",
        "    \"SubjectHB13_BLA\": \"Part2SubjectHB13.h5\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "VHWYayvglxhv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store segments, labels, and sampling frequency for each subject.\n",
        "# Here, WAKE is assigned label 0 and NREM label 1.\n",
        "data_dict = {}\n",
        "\n",
        "for rat, filename in files.items():\n",
        "    segments = []  # to store individual recording segments\n",
        "    labels = []    # to store corresponding state labels\n",
        "    # Open the file for each subject.\n",
        "    with h5py.File(filename, 'r') as f:\n",
        "        print(f\"{rat} keys: {list(f.keys())}\")  # Should show ['NREM', 'WAKE']\n",
        "        print(f['NREM'])\n",
        "        for state in f.keys():\n",
        "            label = 1 if state == \"NREM\" else 0  # assign state label\n",
        "            group = f[state]\n",
        "            for seg_id in group.keys():\n",
        "                seg_data = group[seg_id][()]  # load the segment as a NumPy array\n",
        "                segments.append(seg_data.astype(float))\n",
        "                labels.append(label)\n",
        "\n",
        "    with h5py.File(filename, 'r') as f:\n",
        "        fs = f.attrs.get('fs', 1250)  # default to 1250 Hz if not found\n",
        "    data_dict[rat] = {\"segments\": segments, \"labels\": np.array(labels), \"fs\": fs}\n",
        "    print(f\"{rat}: Loaded {len(segments)} segments\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4fNFYnZnIwX",
        "outputId": "fc68a27c-7602-46e3-c7e2-5b35edf3302b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rat08_HPC keys: ['NREM', 'WAKE']\n",
            "<HDF5 group \"/NREM\" (59 members)>\n",
            "Rat08_HPC: Loaded 96 segments\n",
            "SubjectHB10_BLA keys: ['NREM', 'WAKE']\n",
            "<HDF5 group \"/NREM\" (17 members)>\n",
            "SubjectHB10_BLA: Loaded 55 segments\n",
            "SubjectHB13_BLA keys: ['NREM', 'WAKE']\n",
            "<HDF5 group \"/NREM\" (19 members)>\n",
            "SubjectHB13_BLA: Loaded 41 segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define clip duration (in seconds) and calculate number of samples for 5 seconds.\n",
        "default_fs = 1250  # Use 1250 Hz if no sampling frequency is provided in file\n",
        "clip_duration = 5  # seconds\n",
        "segment_length = int(clip_duration * default_fs)  # samples per clip\n",
        "\n",
        "lfp_clips = {}       # dictionary to hold fixed-length clips (per subject)\n",
        "clip_labels = {}     # dictionary to hold label for each clip\n",
        "\n",
        "for rat, data in data_dict.items():\n",
        "    fs = data.get(\"fs\", default_fs)\n",
        "    seg_list = data[\"segments\"]  # list of variable-length segments\n",
        "    label_list = data[\"labels\"]  # list of corresponding labels\n",
        "    clips = []\n",
        "    labels_out = []\n",
        "    for seg, lab in zip(seg_list, label_list):\n",
        "        if len(seg) >= segment_length:\n",
        "            n_clips = len(seg) // segment_length\n",
        "            seg_trunc = seg[:n_clips * segment_length]  # truncate extra samples\n",
        "            seg_clips = seg_trunc.reshape(n_clips, segment_length)\n",
        "            clips.append(seg_clips)\n",
        "            # Each clip gets the parent segment's label\n",
        "            labels_out.extend([lab] * n_clips)\n",
        "        else:\n",
        "            continue  # skip segments that are too short\n",
        "    # Concatenate clips along axis 0 for each subject\n",
        "    if clips:\n",
        "        clips = np.concatenate(clips, axis=0)\n",
        "    else:\n",
        "        clips = np.empty((0, segment_length))\n",
        "    lfp_clips[rat] = clips\n",
        "    clip_labels[rat] = np.array(labels_out)\n",
        "    print(f\"{rat}: segmented into {clips.shape[0]} clips of 5s each\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnXzucOVnOAy",
        "outputId": "fb75d8d6-4f67-45e7-b914-0becef508d97"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rat08_HPC: segmented into 3682 clips of 5s each\n",
            "SubjectHB10_BLA: segmented into 703 clips of 5s each\n",
            "SubjectHB13_BLA: segmented into 713 clips of 5s each\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to extract features from a clip.\n",
        "# Features: mean, std, skew, kurtosis, and band power in delta, theta, alpha, beta, gamma bands.\n",
        "def extract_features(segment, fs):\n",
        "    mean_val = np.mean(segment)\n",
        "    std_val = np.std(segment)\n",
        "    skew_val = stats.skew(segment)\n",
        "    kurt_val = stats.kurtosis(segment, fisher=False)  # non-Fisher, so normal distribution ~3\n",
        "    freqs, psd = signal.welch(segment, fs=fs, nperseg=fs*2)  # 2-second window\n",
        "    band_powers = []\n",
        "    bands = {\"delta\": (0.5, 4), \"theta\": (4, 8), \"alpha\": (8, 15), \"beta\": (15, 30), \"gamma\": (30, 100)}\n",
        "    for band, (f_low, f_high) in bands.items():\n",
        "        band_mask = (freqs >= f_low) & (freqs < f_high)\n",
        "        # Use np.trapezoid (instead of the deprecated trapz)\n",
        "        band_power = np.trapezoid(psd[band_mask], freqs[band_mask])\n",
        "        band_powers.append(band_power)\n",
        "    return [mean_val, std_val, skew_val, kurt_val] + band_powers\n",
        "\n",
        "# Compute feature matrices for each subject.\n",
        "feature_matrices = {}\n",
        "for rat, clips in lfp_clips.items():\n",
        "    fs = data_dict[rat].get(\"fs\", default_fs)\n",
        "    features = [extract_features(clip, fs) for clip in clips]\n",
        "    feature_matrices[rat] = np.array(features)\n",
        "    print(f\"{rat}: Feature matrix shape = {feature_matrices[rat].shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yid2NhfanPzu",
        "outputId": "69eb240c-1902-4b31-c093-67f975b147ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rat08_HPC: Feature matrix shape = (3682, 9)\n",
            "SubjectHB10_BLA: Feature matrix shape = (703, 9)\n",
            "SubjectHB13_BLA: Feature matrix shape = (713, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use the Rat08_HPC data as an example.\n",
        "features_all = feature_matrices[\"Rat08_HPC\"]   # shape (n_clips, 9)\n",
        "labels_all   = clip_labels[\"Rat08_HPC\"]\n",
        "\n",
        "print(\"Total number of clips: \", features_all.shape[0])\n",
        "\n",
        "# Split data into Train (70%), Validation (15%), and Test (15%)\n",
        "X_train_feat, X_temp, y_train, y_temp = train_test_split(features_all, labels_all,\n",
        "                                                         test_size=0.30, random_state=42, stratify=labels_all)\n",
        "X_val_feat, X_test_feat, y_val, y_test = train_test_split(X_temp, y_temp,\n",
        "                                                         test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(\"Train features shape:\", X_train_feat.shape)\n",
        "print(\"Validation features shape:\", X_val_feat.shape)\n",
        "print(\"Test features shape:\", X_test_feat.shape)\n",
        "\n",
        "# Normalize using StandardScaler based on training features.\n",
        "scaler = StandardScaler().fit(X_train_feat)\n",
        "X_train_feat_norm = scaler.transform(X_train_feat)\n",
        "X_val_feat_norm   = scaler.transform(X_val_feat)\n",
        "X_test_feat_norm  = scaler.transform(X_test_feat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD3tXHPRnRSP",
        "outputId": "2421afb3-9807-4786-c43d-51e95cd2d3c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of clips:  3682\n",
            "Train features shape: (2577, 9)\n",
            "Validation features shape: (552, 9)\n",
            "Test features shape: (553, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple feedforward neural network for sleep state classification.\n",
        "class FFNeuralNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FFNeuralNet, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # two classes: WAKE (0) and NREM (1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Instantiate the model (input_dim = 9 features)\n",
        "model = FFNeuralNet(input_dim=9)\n",
        "print(model)\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors.\n",
        "X_train_t = torch.from_numpy(X_train_feat_norm).float()\n",
        "y_train_t = torch.from_numpy(y_train).long()\n",
        "X_val_t   = torch.from_numpy(X_val_feat_norm).float()\n",
        "y_val_t   = torch.from_numpy(y_val).long()\n",
        "\n",
        "# Set up loss function and optimizer.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 50  # Adjust epochs as needed\n",
        "\n",
        "# Train the model.\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_t)\n",
        "    loss = criterion(outputs, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute training accuracy\n",
        "    _, train_preds = torch.max(outputs, 1)\n",
        "    train_acc = (train_preds == y_train_t).float().mean().item()\n",
        "\n",
        "    # Compute validation accuracy\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val_t)\n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        val_acc = (val_preds == y_val_t).float().mean().item()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch {epoch}: Train Acc = {train_acc:.3f}, Val Acc = {val_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnZifeqdnTNS",
        "outputId": "e427e02e-65d1-43bc-aff4-dfa986e276a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FFNeuralNet(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=9, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=32, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 5: Train Acc = 0.787, Val Acc = 0.793\n",
            "Epoch 10: Train Acc = 0.871, Val Acc = 0.841\n",
            "Epoch 15: Train Acc = 0.894, Val Acc = 0.877\n",
            "Epoch 20: Train Acc = 0.904, Val Acc = 0.880\n",
            "Epoch 25: Train Acc = 0.908, Val Acc = 0.893\n",
            "Epoch 30: Train Acc = 0.920, Val Acc = 0.902\n",
            "Epoch 35: Train Acc = 0.919, Val Acc = 0.902\n",
            "Epoch 40: Train Acc = 0.926, Val Acc = 0.911\n",
            "Epoch 45: Train Acc = 0.931, Val Acc = 0.917\n",
            "Epoch 50: Train Acc = 0.933, Val Acc = 0.909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test data to PyTorch and evaluate performance\n",
        "X_test_t = torch.from_numpy(X_test_feat_norm).float()\n",
        "y_test_t = torch.from_numpy(y_test).long()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_t)\n",
        "    _, test_preds = torch.max(test_outputs, 1)\n",
        "    test_acc = (test_preds == y_test_t).float().mean().item()\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIoayAANnUct",
        "outputId": "8762aa7f-a909-4d22-e762-151bdc634204"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.937\n"
          ]
        }
      ]
    }
  ]
}