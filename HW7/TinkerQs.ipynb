{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NolanRink/CS4540/blob/main/HW7/TinkerQs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Awi7i_rA4_5"
      },
      "source": [
        "# TINKER WITH A NEURAL NETWORK - [LINK](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.28044&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIGGJe5FByNQ"
      },
      "source": [
        "---\n",
        "\n",
        "## TINKER WITH A NEURAL NETWORK\n",
        "\n",
        "### Question 1\n",
        "\n",
        "Before you start the model - Write out the mathematical equation (using the initial weights) to define the output and confirm that it is indeed the boundary shown in the figure (white line separating the blue and orange regions).\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "$$ y = -.05x_{1} - .082x_{2} + 0 $$\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2\n",
        "\n",
        "Now use the smaller button next to the play button to advance the epochs one by one and record the changes. Write out the equations for train and test errors and monitor what happens to them.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "$$ J_{train}(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 $$\n",
        "\n",
        "$$ J_{test}(\\theta) = \\frac{1}{2m_{test}} \\sum_{i=1}^{m_{test}} (h_\\theta(x_{test}^{(i)}) - y_{test}^{(i)})^2 $$\n",
        "\n",
        "| Epoch | Test Loss | Training Loss |\n",
        "| --- | --- | --- |\n",
        "|0|1.597|1.606|\n",
        "|1|0.028|0.033|\n",
        "|2|0.013|0.017|\n",
        "|3|0.008|0.012|\n",
        "|4|0.006|0.009|\n",
        "|5|0.005|0.008|\n",
        "|6|0.004|0.007|\n",
        "\n",
        "<br> <br> <br> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3\n",
        "\n",
        "Run the model till the train and test errors go down sufficiently (how much?) Then write out the mathematical equation (using the final weights) to define the output and confirm that it is indeed the boundary shown in the figure. How does this relate to what was done in class?\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "I trained for 6 epochs until both errors were below 0.01<br><br>\n",
        "Final weights: $$ y = .37x_{1} + .61x_{2} + 0 $$\n",
        "Decision Boundary: $$ x_{2} = -.37x_{1}/.61 $$\n",
        "This is the same decision boundary seen on the website\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 4\n",
        "\n",
        "Change the ‘Activation’ function to sigmoid and repeat steps 1-3. Discuss the differences when using the two different activation functions by following the process epoch-by-epoch.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "$$ z = w_1x_1 + w_2x_2 + b $$\n",
        "$$ y = \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
        "$$ y = \\sigma(0.33x_1 + -0.40x_2 + b) $$\n",
        "\n",
        "\n",
        "\n",
        "| Epoch | Test Loss | Training Loss |\n",
        "| --- | --- | --- |\n",
        "|0|0.686|0.685|\n",
        "|1|0.027|0.028|\n",
        "|2|0.013|0.014|\n",
        "|3|0.009|0.009|\n",
        "|4|0.007|0.007|\n",
        "|5|0.005|0.006|\n",
        "|6|0.004|0.005|\n",
        "\n",
        "Final weights: $$ y = .75x_{1} + .26x_{2} + 0 $$\n",
        "Decision Boundary: $$ x_{2} = -.75x_{1}/.26 $$\n",
        "This is the same decision boundary seen on the website\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 5\n",
        "\n",
        "Now increase the ‘Noise’ slider to the right and report your observations.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "As the Noise slider was increased the test loss and test train values would increase because the noise produced more errors by the model.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 6\n",
        "\n",
        "Try the other datasets with the same single neuron and report your observations including rationale.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "The single neuron on the other  datasets resulted in very large test and training loss. This is likely due to the fact that the neuron is not complex enough to produce a decision boundary that matches the shape of the other datasets.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 7\n",
        "\n",
        "Write down what you understand by a single neuron, i.e., what does it represent?\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "A single neuron takes in a set of inputs and evaluates those input to come up with an output.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 8\n",
        "\n",
        "For the XNOR case, can you find a network that can perform the classification with one neuron? Write down clearly why or why not – important.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "Yes because one of the input feature options is x1x2 which is able to distinguish when just one of x1 or x2 is true.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 9\n",
        "\n",
        "For the dataset named “Circle”, can you find a network that can perform classification with one neuron? Write down clearly why or why not – important.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "Yes because of the input feature x1^2 and x2^2 are able to create a circular decision boundary.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 10\n",
        "\n",
        "Can you, similarly, find a network that can perform classification with one neuron for the dataset titled “Spiral”. Write down clearly why or why not – important.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "No, the spiral dataset is much more complex and without different features or more neurons is not classifiable.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 11\n",
        "\n",
        "If you have fully understood the concepts involved in the previous three items, you will be able to appreciate the first video of Week 4 of coursera with multivariate linear regression. The video  is titled “1. Motivations - Nonlinear hypotheses”. Can you write down a few sentences summarizing\n",
        "what you have learned so far, including the concepts in the cited coursera video. That will set the\n",
        "tone for why we use more than one neuron, i.e., the motivation for using a nonlinear hypothesis.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "As datasets become more complex, more input features will often be needed to classify the datasets. Often a simple way to do this is to add all the second order polynomial features but this does not scale well.\n",
        "<br> <br> <br> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 12\n",
        "\n",
        "Go back now to just X1 and X2 as the features and the XNOR network. Add 1 hidden layer and 1 neuron in the hidden layer and repeat the previous step. What happens and why? Increase the hidden layer neurons in steps of 1 and explain the results for each case, and any explanation for what you see.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "| Hidden Layer Neurons | Observation |\n",
        "| --- | --- |\n",
        "|1| The decision boundary line is now able to increase and decrease its y intercept. |\n",
        "|2| The decision boundary now displays two straight lines |\n",
        "|3| The lines are now curvy and can represent the dataset reasonably well |\n",
        "\n",
        "<br> <br> <br> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 13\n",
        "\n",
        "After completing the XNOR case, try to find the ‘minimal’ network that can work for the other cases.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "| Dataset | Featureset | Hidden Layers |\n",
        "| --- | --- | --- |\n",
        "|Circle| x1^2 , x2^2 | 0 |\n",
        "|XOR| x1x2 | 0 |\n",
        "|Guassian| x1, x2 | 0 |\n",
        "|Spiral|x1, x2, x1^2, x2^2, sin(x1), sin(x2)|2 Neurons(8 then 2)|\n",
        "\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 14\n",
        "\n",
        "Come up with your own ideas of using the ‘Tinker’ toy to design questions that might shed light on the machine learning concepts covered in the course.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "A good question might be: Observe neural nets using different learning rates for different data sets. Does any learning rate stick out as being the best in general?\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 15\n",
        "\n",
        "What does the ‘Test’ and ‘Train’ slider do. Run some of the cases from the previous slide and note the numbers shown on the top of the output figure labeled ‘Test loss’ and ‘Train loss’. Write down the equation for loss and make sure you understand it mathematically. What is the range of train/test loss numbers and how low should you try to get them?\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "The train test slider specifies how much of the data is used for training and how much is used for testing. increasing the slider increases the training data and decreases the testing data. You generally want to decrease test/training loss as much as possible while keeping the values relatively close to avoid under/overfitting.\n",
        "$$ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 16\n",
        "\n",
        "Next vary the ‘Noise’ slider and note your observations for as many of the datasets you can.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "The noise slider spreads the data out and causes more overlap between the orange and blue dots. For all datasets this makes the test and train loss increase.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 17\n",
        "\n",
        "What it ‘batch size’ and how does it affect training – you can try it out as well as read up on it and make notes.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "Batch size is the number of training samples your model processes at once before updating its parameters. During each training iteration (one step of gradient descent), the network computes the loss on those N samples (the batch), sums or averages the gradients, and adjusts the weights accordingly. Then it moves on to the next batch. Decreasing the batch size migth slow training per epoch but can help to escape a local minima. Increasing causes a smoother gradient descent but may require more memory to trian.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 18\n",
        "\n",
        "What does the ‘Regenerate’ button do?\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "It generates new data points in the same general shape as the dataset that was selected\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 19\n",
        "\n",
        "Try to come up with five or more exercises to illustrate the use of these buttons.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "1. Select different datasets (e.g., Spiral, Circles) to see how the data distribution changes and how the model’s decision boundary adapts.\n",
        "2. Adjust the training-to-test ratio slider (e.g., from 80/20 to 50/50) to observe how less training data affects generalization and test loss.\n",
        "3. Increase the noise slider from 0 up to 50+ to watch the data become more scattered and see if the model can still separate the classes.\n",
        "4. Change the batch size slider (e.g., from 1 to 20) to compare how updates become smoother or noisier and how quickly the model converges.\n",
        "5. Press Regenerate to create a new dataset with the same settings, then check if the network still learns consistently.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 20\n",
        "\n",
        "What does the ‘Test’ and ‘Train’ slider do. Run some of the cases from the previous slide and note the numbers shown on the top of the output figure labeled ‘Test loss’ and ‘Train loss’. Write down the equation for loss and make sure you understand it mathematically. What is the range of train/test loss numbers and how low should you try to get them?\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "The train test slider specifies how much of the data is used for training and how much is used for testing. increasing the slider increases the training data and decreases the testing data. You generally want to decrease test/training loss as much as possible while keeping the values relatively close to avoid under/overfitting.\n",
        "$$ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 21\n",
        "\n",
        "Next vary the ‘Noise’ slider and note your observations for as many of the datasets as you can.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "The noise slider spreads the data out and causes more overlap between the orange and blue dots. For all datasets this makes the test and train loss increase.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 22\n",
        "\n",
        "What it ‘batch size’ and how does it affect training – you can try it out as well as read up on it and make notes.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "Batch size is the number of training samples your model processes at once before updating its parameters. During each training iteration (one step of gradient descent), the network computes the loss on those N samples (the batch), sums or averages the gradients, and adjusts the weights accordingly. Then it moves on to the next batch. Decreasing the batch size migth slow training per epoch but can help to escape a local minima. Increasing causes a smoother gradient descent but may require more memory to trian.\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 23\n",
        "\n",
        "What does the ‘Regenerate’ button do?\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "It generates new data points in the same general shape as the dataset that was selected\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 24\n",
        "\n",
        "Next complete the Tinker Playground exercises by Google – [HERE](https://developers.google.com/machine-learning/crash-course/neural-networks/interactive-exercises)\n",
        "<br> <br> <br> <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 25\n",
        "\n",
        "Finally, good to summarize the key concepts that this excellent self-learning tool helps illustrate. Do this in a Colab module that you can then use as a tool to teach others, including at your future workplace!\n",
        "\n",
        "<br>\n",
        "\n",
        "**Answer:**\n",
        "# Key Neural Network Concepts\n",
        "\n",
        "The file explores fundamental concepts of neural networks through hands-on experimentation with TensorFlow Playground. At its core, a single neuron performs a basic computation: taking weighted inputs plus a bias, followed by an activation function, expressed mathematically as:\n",
        "\n",
        "$$ [y = f(sum_{i=1}^n w_ix_i + b)] $$\n",
        "\n",
        "The choice between activation functions, such as linear versus sigmoid, significantly impacts the network's behavior and output range. Model performance is measured through loss functions, particularly the Mean Squared Error (MSE), defined as:\n",
        "\n",
        "$$ [J_{train}(theta) = \\frac{1}{2m} sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2] $$\n",
        "\n",
        "where lower values indicate better performance.\n",
        "\n",
        "A crucial concept is **linear separability** - single neurons can only solve linearly separable problems, while more complex patterns like XNOR, Circle, or Spiral datasets require multiple neurons arranged in hidden layers. The architecture of a neural network must match the complexity of the problem it's trying to solve, with simpler problems potentially solvable by a single neuron while more complex patterns demand additional layers and neurons.\n",
        "\n",
        "Several practical considerations affect training effectiveness:\n",
        "- Noise in the data impacts model performance and increases loss\n",
        "- Batch size influences training efficiency\n",
        "- Train/test split helps evaluate how well the model generalizes to new data\n",
        "- Learning rate determines how quickly the model adapts during training\n",
        "\n",
        "Through interactive experimentation with TensorFlow Playground, users can visualize these concepts in action, understanding how different architectures, hyperparameters, and activation functions shape the network's decision boundaries and overall performance.\n",
        "\n",
        "For classification tasks using sigmoid activation, the output is bounded between 0 and 1:\n",
        "\n",
        "$$[y = sigma(z) = \\frac{1}{1 + e^{-z}}]$$\n",
        "\n",
        "where $$(z = w_1x_1 + w_2x_2 + b)$$represents the weighted sum of inputs plus bias.\n",
        "<br> <br> <br> <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOcYdbpnOAQJqWFgS4pEeD3",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
