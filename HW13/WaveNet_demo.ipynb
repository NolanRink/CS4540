{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NolanRink/CS4540/blob/main/HW13/WaveNet_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7-6GBG0CqG7"
      },
      "source": [
        "This is notebook gives a quick overview of this WaveNet implementation, i.e. creating the model and the data set, training the model and generating samples from it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Vichoko/pytorch-wavenet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr9BcM1UDBpG",
        "outputId": "bd86b207-a131-4dc8-bbef-ec901def8305"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pytorch-wavenet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "jRm8o9LYCqG-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"pytorch-wavenet\")\n",
        "\n",
        "import torch\n",
        "from wavenet_model import *\n",
        "from audio_data import WavenetDataset\n",
        "from wavenet_training import *\n",
        "from model_logging import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw7Jo_huCqHA"
      },
      "source": [
        "## Model\n",
        "This is an implementation of WaveNet as it was described in the original paper (https://arxiv.org/abs/1609.03499). Each layer looks like this:\n",
        "\n",
        "```\n",
        "            |----------------------------------------|      *residual*\n",
        "            |                                        |\n",
        "            |    |-- conv -- tanh --|                |\n",
        " -> dilate -|----|                  * ----|-- 1x1 -- + -->  *input*\n",
        "                 |-- conv -- sigm --|     |\n",
        "                                         1x1\n",
        "                                          |\n",
        " ---------------------------------------> + ------------->  *skip*\n",
        "```\n",
        "\n",
        "Each layer dilates the input by a factor of two. After each block the dilation is reset and start from one. You can define the number of layers in each block (``layers``) and the number of blocks (``blocks``). The blocks are followed by two 1x1 convolutions and a softmax output function.\n",
        "Because of the dilation operation, the independent output for multiple successive samples can be calculated efficiently. With ``output_length``, you can define the number these outputs. Empirically, it seems that a large number of skip channels is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhQDk5qQCqHA",
        "outputId": "556d8b04-35d4-479e-b829-0a10eae97cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use gpu\n"
          ]
        }
      ],
      "source": [
        "# initialize cuda option\n",
        "dtype = torch.FloatTensor # data type\n",
        "ltype = torch.LongTensor # label type\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "\n",
        "    print('use gpu')\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "    ltype = torch.cuda.LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXppgCGYCqHB",
        "outputId": "43b276ce-c024-4a4e-d064-e23682dad5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  WaveNetModel(\n",
            "  (filter_convs): ModuleList(\n",
            "    (0-15): 16 x Conv1d(24, 24, kernel_size=(2,), stride=(1,))\n",
            "  )\n",
            "  (gate_convs): ModuleList(\n",
            "    (0-15): 16 x Conv1d(24, 24, kernel_size=(2,), stride=(1,))\n",
            "  )\n",
            "  (residual_convs): ModuleList(\n",
            "    (0-15): 16 x Conv1d(24, 24, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (skip_convs): ModuleList(\n",
            "    (0-15): 16 x Conv1d(24, 64, kernel_size=(1,), stride=(1,))\n",
            "  )\n",
            "  (start_conv): Conv1d(256, 24, kernel_size=(1,), stride=(1,))\n",
            "  (end_conv_1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
            "  (end_conv_2): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n",
            ")\n",
            "receptive field:  511\n",
            "parameter count:  89528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/pytorch-wavenet/wavenet_modules.py:53: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  self.data = Variable(dtype(num_channels, max_length).zero_())\n"
          ]
        }
      ],
      "source": [
        "model = WaveNetModel(layers=8,\n",
        "                     blocks=2,\n",
        "                     dilation_channels=24,\n",
        "                     residual_channels=24,\n",
        "                     skip_channels=64,\n",
        "                     end_channels=32,\n",
        "                     output_length=16,\n",
        "                     dtype=dtype,\n",
        "                     bias=True)\n",
        "# model = load_latest_model_from('snapshots', use_cuda=use_cuda)\n",
        "\n",
        "print('model: ', model)\n",
        "print('receptive field: ', model.receptive_field)\n",
        "print('parameter count: ', model.parameter_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY7PTiDVCqHB"
      },
      "source": [
        "## Data Set\n",
        "To create the data set, you have to specify a path to a data set file. If this file already exists it will be used, if not it will be generated. If you want to generate the data set file (a ``.npz`` file), you have to specify the directory (``file_location``) in which all the audio files you want to use are located. The attribute ``target_length`` specifies the number of successive samples are used as a target and corresponds to the output length of the model. The ``item_length`` defines the number of samples in each item of the dataset and should always be ``model.receptive_field + model.output_length - 1``.\n",
        "\n",
        "```\n",
        "          |----receptive_field----|\n",
        "                                |--output_length--|\n",
        "example:  | | | | | | | | | | | | | | | | | | | | |\n",
        "target:                           | | | | | | | | | |  \n",
        "```\n",
        "To create a test set, you should define a ``test_stride``. Then each ``test_stride``th item will be assigned to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wepn6k5LCqHC",
        "outputId": "b141b99c-8622-4dd6-c024-dda4836a6d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one hot input\n",
            "the dataset has 598436 items\n"
          ]
        }
      ],
      "source": [
        "data = WavenetDataset(dataset_file='pytorch-wavenet/train_samples/bach_chaconne/dataset.npz',\n",
        "                      item_length=model.receptive_field + model.output_length - 1,\n",
        "                      target_length=model.output_length,\n",
        "                      file_location='pytorch-wavenet/train_samples/bach_chaconne',\n",
        "                      test_stride=500)\n",
        "print('the dataset has ' + str(len(data)) + ' items')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAXavQP_CqHC"
      },
      "source": [
        "## Training and Logging\n",
        "This implementation supports logging with TensorBoard (you need to have TensorFlow installed). You can even generate audio samples from the current snapshot of the model during training. This will happen in a background thread on the cpu, so it will not interfere with the actual training but will be rather slow. If you don't have TensorFlow, you can use the standard logger that will print out to the console.\n",
        "The trainer uses Adam as default optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "KyNI6gLkCqHD"
      },
      "outputs": [],
      "source": [
        "def generate_and_log_samples(step):\n",
        "    sample_length=32000\n",
        "    gen_model = load_latest_model_from('snapshots', use_cuda=False)\n",
        "    print(\"start generating...\")\n",
        "    samples = generate_audio(gen_model,\n",
        "                             length=sample_length,\n",
        "                             temperatures=[0.5])\n",
        "    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
        "    logger.audio_summary('temperature_0.5', tf_samples, step, sr=16000)\n",
        "\n",
        "    samples = generate_audio(gen_model,\n",
        "                             length=sample_length,\n",
        "                             temperatures=[1.])\n",
        "    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
        "    logger.audio_summary('temperature_1.0', tf_samples, step, sr=16000)\n",
        "    print(\"audio clips generated\")\n",
        "\n",
        "\n",
        "# logger = TensorboardLogger(log_interval=200,\n",
        "#                            validation_interval=400,\n",
        "#                            generate_interval=1000,\n",
        "#                            generate_function=generate_and_log_samples,\n",
        "#                            log_dir=\"logs/chaconne_model\")\n",
        "\n",
        "logger = Logger(log_interval=200,\n",
        "                validation_interval=400,\n",
        "                generate_interval=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/pytorch-wavenet/train_samples/bach_chaconne\n",
        "\n",
        "!wget -q \\\n",
        "    https://raw.githubusercontent.com/vincentherrmann/pytorch-wavenet/master/train_samples/bach_chaconne/dataset.npz \\\n",
        "    -O /content/pytorch-wavenet/train_samples/bach_chaconne/dataset.npz"
      ],
      "metadata": {
        "id": "PH8WJSE-PWkz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq8ozoF4CqHD",
        "outputId": "31942812-4995-4f98-9cad-1fa979cf2a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD is now /content\n",
            "start training...\n",
            "epoch 0\n",
            "one training step does take approximately 0.21059401750564577 seconds)\n",
            "loss at step 200: tensor(6.7628, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 400: tensor(3.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.6228034019470217\n",
            "validation accuracy: 8.585279399499584%\n",
            "loss at step 600: tensor(3.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 800: tensor(3.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.6040302085876466\n",
            "validation accuracy: 8.731234361968307%\n",
            "loss at step 1000: tensor(3.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 1200: tensor(3.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.5527006022135414\n",
            "validation accuracy: 8.997080900750626%\n",
            "loss at step 1400: tensor(3.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 1600: tensor(3.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.5205342896779377\n",
            "validation accuracy: 8.981442869057547%\n",
            "loss at step 1800: tensor(3.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 2000: tensor(3.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.4963098907470704\n",
            "validation accuracy: 9.351542952460383%\n",
            "loss at step 2200: tensor(3.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 2400: tensor(3.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.479015833536784\n",
            "validation accuracy: 9.492285237698082%\n",
            "loss at step 2600: tensor(3.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 2800: tensor(3.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.4840156650543213\n",
            "validation accuracy: 9.189949958298582%\n",
            "loss at step 3000: tensor(3.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 3200: tensor(3.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.4431473128000896\n",
            "validation accuracy: 9.335904920767305%\n",
            "loss at step 3400: tensor(3.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 3600: tensor(3.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.4306837781270345\n",
            "validation accuracy: 9.487072560467055%\n",
            "loss at step 3800: tensor(3.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 4000: tensor(3.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.412769231796265\n",
            "validation accuracy: 9.700792326939116%\n",
            "loss at step 4200: tensor(3.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 4400: tensor(3.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.3854297987620035\n",
            "validation accuracy: 9.742493744787323%\n",
            "loss at step 4600: tensor(3.2053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 4800: tensor(3.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.367826312383016\n",
            "validation accuracy: 9.893661384487071%\n",
            "loss at step 5000: tensor(3.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 5200: tensor(3.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.352177206675212\n",
            "validation accuracy: 10.102168473728106%\n",
            "loss at step 5400: tensor(3.1746, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 5600: tensor(3.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.354656972885132\n",
            "validation accuracy: 10.003127606338616%\n",
            "loss at step 5800: tensor(3.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 6000: tensor(3.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.341127300262451\n",
            "validation accuracy: 10.133444537114263%\n",
            "loss at step 6200: tensor(3.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 6400: tensor(3.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.337657985687256\n",
            "validation accuracy: 10.331526271893244%\n",
            "loss at step 6600: tensor(3.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 6800: tensor(3.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.3473848311106362\n",
            "validation accuracy: 10.070892410341951%\n",
            "loss at step 7000: tensor(3.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 7200: tensor(3.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.3037643496195477\n",
            "validation accuracy: 10.3628023352794%\n",
            "loss at step 7400: tensor(3.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 7600: tensor(3.1443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.283230053583781\n",
            "validation accuracy: 10.529608006672227%\n",
            "loss at step 7800: tensor(3.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 8000: tensor(3.1452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.30828621228536\n",
            "validation accuracy: 10.326313594662219%\n",
            "loss at step 8200: tensor(3.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 8400: tensor(3.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2705995559692385\n",
            "validation accuracy: 10.633861551292743%\n",
            "loss at step 8600: tensor(3.1265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 8800: tensor(3.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2557427946726483\n",
            "validation accuracy: 10.57652210175146%\n",
            "loss at step 9000: tensor(3.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 9200: tensor(3.1172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2470650386810305\n",
            "validation accuracy: 10.581734778982485%\n",
            "loss at step 9400: tensor(3.1256, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 9600: tensor(3.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2578709443410236\n",
            "validation accuracy: 10.48790658882402%\n",
            "loss at step 9800: tensor(3.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 10000: tensor(3.1032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.241439126332601\n",
            "validation accuracy: 11.087364470391993%\n",
            "loss at step 10200: tensor(3.0934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 10400: tensor(3.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2681349404652913\n",
            "validation accuracy: 10.581734778982485%\n",
            "loss at step 10600: tensor(3.0930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 10800: tensor(3.0926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2280135599772137\n",
            "validation accuracy: 11.103002502085072%\n",
            "loss at step 11000: tensor(3.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 11200: tensor(3.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.243865795135498\n",
            "validation accuracy: 10.717264386989157%\n",
            "loss at step 11400: tensor(3.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 11600: tensor(3.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2588790321350096\n",
            "validation accuracy: 10.472268557130942%\n",
            "loss at step 11800: tensor(3.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 12000: tensor(3.0749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.2202498213450115\n",
            "validation accuracy: 10.623436196830692%\n",
            "loss at step 12200: tensor(3.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 12400: tensor(3.0789, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.235002498626709\n",
            "validation accuracy: 10.722477064220183%\n",
            "loss at step 12600: tensor(3.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 12800: tensor(3.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.193628489176432\n",
            "validation accuracy: 11.436613844870726%\n",
            "loss at step 13000: tensor(3.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 13200: tensor(3.0788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.196769584019979\n",
            "validation accuracy: 11.019599666388658%\n",
            "loss at step 13400: tensor(3.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 13600: tensor(3.0870, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.216350285212199\n",
            "validation accuracy: 10.540033361134277%\n",
            "loss at step 13800: tensor(3.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 14000: tensor(3.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.20007511138916\n",
            "validation accuracy: 11.306296914095078%\n",
            "loss at step 14200: tensor(3.0607, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 14400: tensor(3.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.190854072570801\n",
            "validation accuracy: 10.858006672226855%\n",
            "loss at step 14600: tensor(3.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 14800: tensor(3.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.185572477976481\n",
            "validation accuracy: 10.91534612176814%\n",
            "loss at step 15000: tensor(3.0351, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 15200: tensor(3.0463, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.185618454615275\n",
            "validation accuracy: 11.353211009174311%\n",
            "loss at step 15400: tensor(3.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 15600: tensor(3.0590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.18221666653951\n",
            "validation accuracy: 11.238532110091743%\n",
            "loss at step 15800: tensor(3.0324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 16000: tensor(3.0438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1857230917612713\n",
            "validation accuracy: 11.113427856547123%\n",
            "loss at step 16200: tensor(3.0441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 16400: tensor(3.0429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.179783074061076\n",
            "validation accuracy: 11.207256046705588%\n",
            "loss at step 16600: tensor(3.0308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 16800: tensor(3.0380, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.175090659459432\n",
            "validation accuracy: 11.134278565471226%\n",
            "loss at step 17000: tensor(3.0447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 17200: tensor(3.0518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.157701718012492\n",
            "validation accuracy: 11.248957464553795%\n",
            "loss at step 17400: tensor(3.0454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 17600: tensor(3.0286, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.162612460454305\n",
            "validation accuracy: 10.988323603002502%\n",
            "loss at step 17800: tensor(3.0330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 18000: tensor(3.0274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.148709983825684\n",
            "validation accuracy: 11.15512927439533%\n",
            "loss at step 18200: tensor(3.0005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 18400: tensor(3.0230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1431402937571207\n",
            "validation accuracy: 11.530442035029191%\n",
            "loss at step 18600: tensor(3.0180, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 18800: tensor(3.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.15316419283549\n",
            "validation accuracy: 11.488740617180984%\n",
            "loss at step 19000: tensor(3.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 19200: tensor(3.0268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1305505243937173\n",
            "validation accuracy: 11.613844870725606%\n",
            "loss at step 19400: tensor(3.0434, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 19600: tensor(3.0238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1362822977701823\n",
            "validation accuracy: 11.509591326105086%\n",
            "loss at step 19800: tensor(3.0251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 20000: tensor(2.9993, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.154721164703369\n",
            "validation accuracy: 11.488740617180984%\n",
            "loss at step 20200: tensor(3.0037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 20400: tensor(3.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.130119597117106\n",
            "validation accuracy: 11.655546288573811%\n",
            "loss at step 20600: tensor(3.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 20800: tensor(3.0211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1109720706939696\n",
            "validation accuracy: 11.85884070058382%\n",
            "loss at step 21000: tensor(3.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 21200: tensor(2.9949, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.126995751063029\n",
            "validation accuracy: 11.582568807339449%\n",
            "loss at step 21400: tensor(3.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 21600: tensor(2.9948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.11411997795105\n",
            "validation accuracy: 12.171601334445372%\n",
            "loss at step 21800: tensor(3.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 22000: tensor(3.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.111283915837606\n",
            "validation accuracy: 11.619057547956631%\n",
            "loss at step 22200: tensor(3.0055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 22400: tensor(3.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1115445264180503\n",
            "validation accuracy: 12.051709758131777%\n",
            "loss at step 22600: tensor(3.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 22800: tensor(3.0048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1214004071553547\n",
            "validation accuracy: 11.561718098415346%\n",
            "loss at step 23000: tensor(2.9981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 23200: tensor(2.9963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1691337617238364\n",
            "validation accuracy: 8.731234361968307%\n",
            "loss at step 23400: tensor(2.9792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 23600: tensor(3.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0964349524180093\n",
            "validation accuracy: 12.103836530442035%\n",
            "loss at step 23800: tensor(2.9948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 24000: tensor(2.9921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.097097504933675\n",
            "validation accuracy: 11.645120934111759%\n",
            "loss at step 24200: tensor(2.9934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 24400: tensor(3.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0897071679433186\n",
            "validation accuracy: 11.916180150125104%\n",
            "loss at step 24600: tensor(2.9957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 24800: tensor(2.9842, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.084490025838216\n",
            "validation accuracy: 12.34883236030025%\n",
            "loss at step 25000: tensor(2.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 25200: tensor(2.9811, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0878539498647055\n",
            "validation accuracy: 12.166388657214346%\n",
            "loss at step 25400: tensor(2.9794, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 25600: tensor(2.9791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1049963665008544\n",
            "validation accuracy: 11.811926605504587%\n",
            "loss at step 25800: tensor(2.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 26000: tensor(2.9750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0785629558563232\n",
            "validation accuracy: 12.343619683069225%\n",
            "loss at step 26200: tensor(2.9595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 26400: tensor(2.9804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.088299357096354\n",
            "validation accuracy: 11.942243536280234%\n",
            "loss at step 26600: tensor(2.9799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 26800: tensor(2.9761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0827220980326335\n",
            "validation accuracy: 11.603419516263552%\n",
            "loss at step 27000: tensor(2.9846, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 27200: tensor(2.9576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.078984479904175\n",
            "validation accuracy: 11.916180150125104%\n",
            "loss at step 27400: tensor(2.9608, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 27600: tensor(2.9692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.105627743403117\n",
            "validation accuracy: 12.067347789824854%\n",
            "loss at step 27800: tensor(2.9699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 28000: tensor(2.9625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.070490452448527\n",
            "validation accuracy: 11.645120934111759%\n",
            "loss at step 28200: tensor(2.9850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 28400: tensor(2.9508, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0617389806111652\n",
            "validation accuracy: 12.140325271059215%\n",
            "loss at step 28600: tensor(2.9722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 28800: tensor(2.9583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.064124511082967\n",
            "validation accuracy: 12.1976647206005%\n",
            "loss at step 29000: tensor(2.9565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 29200: tensor(2.9895, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.1265364774068196\n",
            "validation accuracy: 12.051709758131777%\n",
            "loss at step 29400: tensor(2.9640, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 29600: tensor(2.9587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.180380719502767\n",
            "validation accuracy: 8.699958298582152%\n",
            "loss at step 29800: tensor(2.9658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 30000: tensor(2.9478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0528699938456216\n",
            "validation accuracy: 12.494787322768975%\n",
            "loss at step 30200: tensor(2.9387, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 30400: tensor(2.9418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0628079573313394\n",
            "validation accuracy: 12.020433694745622%\n",
            "loss at step 30600: tensor(2.9471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 30800: tensor(2.9418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.057922042210897\n",
            "validation accuracy: 12.067347789824854%\n",
            "loss at step 31000: tensor(2.9342, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 31200: tensor(2.9336, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.042173744837443\n",
            "validation accuracy: 12.025646371976647%\n",
            "loss at step 31400: tensor(2.9514, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 31600: tensor(2.9398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.039051316579183\n",
            "validation accuracy: 12.791909924937448%\n",
            "loss at step 31800: tensor(2.9296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 32000: tensor(2.9417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0474353408813477\n",
            "validation accuracy: 12.55212677231026%\n",
            "loss at step 32200: tensor(2.9378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 32400: tensor(2.9447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.081577711105347\n",
            "validation accuracy: 12.354045037531277%\n",
            "loss at step 32600: tensor(2.9331, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 32800: tensor(2.9353, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0492370669047038\n",
            "validation accuracy: 12.281067556296914%\n",
            "loss at step 33000: tensor(2.9546, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 33200: tensor(2.9213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.044888416926066\n",
            "validation accuracy: 12.145537948290242%\n",
            "loss at step 33400: tensor(2.9272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 33600: tensor(2.9394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0147803846995034\n",
            "validation accuracy: 12.614678899082568%\n",
            "loss at step 33800: tensor(2.9247, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 34000: tensor(2.9240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.022033685048421\n",
            "validation accuracy: 12.24979149291076%\n",
            "loss at step 34200: tensor(2.9445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 34400: tensor(2.9287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0180455843607583\n",
            "validation accuracy: 12.546914095079234%\n",
            "loss at step 34600: tensor(2.9212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 34800: tensor(2.9342, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.021643959681193\n",
            "validation accuracy: 12.333194328607172%\n",
            "loss at step 35000: tensor(2.9305, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 35200: tensor(2.9223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0259580834706625\n",
            "validation accuracy: 12.614678899082568%\n",
            "loss at step 35400: tensor(2.9450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 35600: tensor(2.9029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0207814184824624\n",
            "validation accuracy: 12.281067556296914%\n",
            "loss at step 35800: tensor(2.9166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 36000: tensor(2.9167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0057589785257974\n",
            "validation accuracy: 12.432235195996665%\n",
            "loss at step 36200: tensor(2.9170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 36400: tensor(2.9225, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0165215714772544\n",
            "validation accuracy: 12.192452043369475%\n",
            "loss at step 36600: tensor(2.9084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 36800: tensor(2.9002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.997357536951701\n",
            "validation accuracy: 12.91701417848207%\n",
            "loss at step 37000: tensor(2.9144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 37200: tensor(2.8984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0024249903361\n",
            "validation accuracy: 12.885738115095913%\n",
            "loss at step 37400: tensor(2.9047, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch 1\n",
            "loss at step 37600: tensor(2.9221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0260345363616943\n",
            "validation accuracy: 12.520850708924103%\n",
            "loss at step 37800: tensor(2.9133, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 38000: tensor(2.9116, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 3.0629778321584067\n",
            "validation accuracy: 12.43744787322769%\n",
            "loss at step 38200: tensor(2.9077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 38400: tensor(2.9141, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.999183940887451\n",
            "validation accuracy: 12.703294412010008%\n",
            "loss at step 38600: tensor(2.9094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 38800: tensor(2.9113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.995015516281128\n",
            "validation accuracy: 12.906588824020016%\n",
            "loss at step 39000: tensor(2.8934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 39200: tensor(2.8939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9926543935139973\n",
            "validation accuracy: 12.55212677231026%\n",
            "loss at step 39400: tensor(2.8943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 39600: tensor(2.9063, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9807512124379474\n",
            "validation accuracy: 12.922226855713095%\n",
            "loss at step 39800: tensor(2.8998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 40000: tensor(2.8923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.980070209503174\n",
            "validation accuracy: 13.250625521267722%\n",
            "loss at step 40200: tensor(2.8821, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 40400: tensor(2.8900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.986840705871582\n",
            "validation accuracy: 12.870100083402836%\n",
            "loss at step 40600: tensor(2.8738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 40800: tensor(2.9112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9894858519236247\n",
            "validation accuracy: 12.73978315262719%\n",
            "loss at step 41000: tensor(2.8876, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 41200: tensor(2.8682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9735849412282307\n",
            "validation accuracy: 13.297539616346956%\n",
            "loss at step 41400: tensor(2.9003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 41600: tensor(2.8658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9977161502838134\n",
            "validation accuracy: 12.755421184320268%\n",
            "loss at step 41800: tensor(2.8966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 42000: tensor(2.8880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9668144607543945\n",
            "validation accuracy: 13.036905754795663%\n",
            "loss at step 42200: tensor(2.9082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 42400: tensor(2.8932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.987665398915609\n",
            "validation accuracy: 12.734570475396165%\n",
            "loss at step 42600: tensor(2.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 42800: tensor(2.8828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.97387344678243\n",
            "validation accuracy: 12.854462051709758%\n",
            "loss at step 43000: tensor(2.8820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 43200: tensor(2.8842, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9552827294667563\n",
            "validation accuracy: 13.162010008340284%\n",
            "loss at step 43400: tensor(2.8977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 43600: tensor(2.8667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9639501476287844\n",
            "validation accuracy: 13.078607172643869%\n",
            "loss at step 43800: tensor(2.8854, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 44000: tensor(2.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9581144142150877\n",
            "validation accuracy: 12.890950792326938%\n",
            "loss at step 44200: tensor(2.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 44400: tensor(2.8823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.947468179066976\n",
            "validation accuracy: 12.995204336947456%\n",
            "loss at step 44600: tensor(2.8836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 44800: tensor(2.8778, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9565343697865805\n",
            "validation accuracy: 13.318390325271059%\n",
            "loss at step 45000: tensor(2.8734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 45200: tensor(2.8908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9604483032226563\n",
            "validation accuracy: 12.583402835696415%\n",
            "loss at step 45400: tensor(2.8767, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 45600: tensor(2.8809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.957198505401611\n",
            "validation accuracy: 12.750208507089242%\n",
            "loss at step 45800: tensor(2.8747, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 46000: tensor(2.8670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.962664079666138\n",
            "validation accuracy: 12.91701417848207%\n",
            "loss at step 46200: tensor(2.8756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 46400: tensor(2.8697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.96301762898763\n",
            "validation accuracy: 12.932652210175148%\n",
            "loss at step 46600: tensor(2.8646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 46800: tensor(2.8608, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.955890293121338\n",
            "validation accuracy: 13.156797331109257%\n",
            "loss at step 47000: tensor(2.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 47200: tensor(2.8541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9580783875783285\n",
            "validation accuracy: 12.68765638031693%\n",
            "loss at step 47400: tensor(2.8584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 47600: tensor(2.8664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.962911408742269\n",
            "validation accuracy: 13.094245204336946%\n",
            "loss at step 47800: tensor(2.8725, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 48000: tensor(2.8530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9425371869405113\n",
            "validation accuracy: 13.407005838198499%\n",
            "loss at step 48200: tensor(2.8500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 48400: tensor(2.8536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.93105588277181\n",
            "validation accuracy: 13.135946622185154%\n",
            "loss at step 48600: tensor(2.8530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 48800: tensor(2.8462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.941959867477417\n",
            "validation accuracy: 13.062969140950791%\n",
            "loss at step 49000: tensor(2.8585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 49200: tensor(2.8523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9582349109649657\n",
            "validation accuracy: 12.583402835696415%\n",
            "loss at step 49400: tensor(2.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 49600: tensor(2.8474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9293838818868\n",
            "validation accuracy: 13.182860717264386%\n",
            "loss at step 49800: tensor(2.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 50000: tensor(2.8544, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.921457341512044\n",
            "validation accuracy: 13.751042535446206%\n",
            "loss at step 50200: tensor(2.8448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 50400: tensor(2.8512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.941218557357788\n",
            "validation accuracy: 13.219349457881568%\n",
            "loss at step 50600: tensor(2.8424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 50800: tensor(2.8535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9363836097717284\n",
            "validation accuracy: 13.46955796497081%\n",
            "loss at step 51000: tensor(2.8377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 51200: tensor(2.8503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9282002449035645\n",
            "validation accuracy: 13.250625521267722%\n",
            "loss at step 51400: tensor(2.8398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 51600: tensor(2.8463, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9233263111114502\n",
            "validation accuracy: 13.516472060050042%\n",
            "loss at step 51800: tensor(2.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 52000: tensor(2.8410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9196113872528078\n",
            "validation accuracy: 13.297539616346956%\n",
            "loss at step 52200: tensor(2.8558, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 52400: tensor(2.8598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9167804781595867\n",
            "validation accuracy: 13.537322768974144%\n",
            "loss at step 52600: tensor(2.8440, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "loss at step 52800: tensor(2.8394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "validation loss: 2.9221323490142823\n",
            "validation accuracy: 13.63115095913261%\n",
            "loss at step 53000: tensor(2.8362, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model.cuda()\n",
        "trainer = WavenetTrainer(model=model,\n",
        "                         dataset=data,\n",
        "                         lr=0.001,\n",
        "                         snapshot_path='/content/pytorch-wavenet/snapshots',\n",
        "                         snapshot_name='chaconne_model',\n",
        "                         snapshot_interval=1000,\n",
        "                         logger=logger,\n",
        "                         dtype=dtype,\n",
        "                         ltype=ltype)\n",
        "\n",
        "import os\n",
        "print(\"CWD is now\", os.getcwd())\n",
        "print('start training...')\n",
        "trainer.train(batch_size=16,epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dN5fVWNCqHD"
      },
      "source": [
        "## Generating\n",
        "This model has the Fast Wavenet Generation Algorithm (https://arxiv.org/abs/1611.09482) implemented. This might run faster on the cpu. You can give some starting data (of at least the length of receptive field) or let the model generate from zero. In my experience, a temperature between 0.5 and 1.0 yields the best results, but this may depend on the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lShw06LYCqHD",
        "outputId": "36c27b4f-3b34-4d56-d019-9f7aa96233c1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a9a25252ed99>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m250000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# use start data from the data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstart_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# convert one hot vectors to integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprog_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"% generated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "start_data = data[250000][0] # use start data from the data set\n",
        "start_data = torch.max(start_data, 0)[1] # convert one hot vectors to integers\n",
        "\n",
        "def prog_callback(step, total_steps):\n",
        "    print(str(100 * step // total_steps) + \"% generated\")\n",
        "\n",
        "model.cpu()\n",
        "generated = model.generate_fast(num_samples=160000,\n",
        "                                 first_samples=start_data,\n",
        "                                 progress_callback=prog_callback,\n",
        "                                 progress_interval=1000,\n",
        "                                 temperature=1.0,\n",
        "                                 regularize=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SgW0vopWCqHE"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "ipd.Audio(generated, rate=16000)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}